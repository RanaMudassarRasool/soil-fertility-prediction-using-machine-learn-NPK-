{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7845151,"sourceType":"datasetVersion","datasetId":4599836}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ANN for Soil Fertility Prediction","metadata":{}},{"cell_type":"code","source":"#  ANN for Soil Fertility Prediction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/npk-crop-recmendation/crop_recommendation.csv')\n\n# Splitting features (X) and target (y)\nX = data[['N', 'P', 'K', 'ph', 'humidity', 'temperature', 'rainfall']].values\ny = data['label'].values\n\n# Encoding the target if it's categorical\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)\n\n# Splitting the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Scaling features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Building the ANN model\nmodel = Sequential()\nmodel.add(Dense(16, activation='relu', input_dim=X_train.shape[1]))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(len(np.unique(y)), activation='softmax'))  # Adjust output neurons for classification\n\n# Compiling the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Training the model\nmodel.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n\n# Evaluating the model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-01T15:02:14.793566Z","iopub.execute_input":"2025-01-01T15:02:14.794045Z","iopub.status.idle":"2025-01-01T15:02:22.995207Z","shell.execute_reply.started":"2025-01-01T15:02:14.794007Z","shell.execute_reply":"2025-01-01T15:02:22.994220Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1240 - loss: 3.0048 - val_accuracy: 0.2159 - val_loss: 2.8897\nEpoch 2/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2100 - loss: 2.8355 - val_accuracy: 0.3136 - val_loss: 2.7253\nEpoch 3/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2786 - loss: 2.6793 - val_accuracy: 0.3795 - val_loss: 2.5039\nEpoch 4/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3913 - loss: 2.4080 - val_accuracy: 0.4386 - val_loss: 2.2171\nEpoch 5/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4635 - loss: 2.1129 - val_accuracy: 0.5568 - val_loss: 1.8916\nEpoch 6/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 1.7692 - val_accuracy: 0.6045 - val_loss: 1.5881\nEpoch 7/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6579 - loss: 1.4756 - val_accuracy: 0.7136 - val_loss: 1.3285\nEpoch 8/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 1.2110 - val_accuracy: 0.7636 - val_loss: 1.1204\nEpoch 9/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7701 - loss: 1.0507 - val_accuracy: 0.7932 - val_loss: 0.9576\nEpoch 10/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.8617 - val_accuracy: 0.8114 - val_loss: 0.8294\nEpoch 11/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8549 - loss: 0.7348 - val_accuracy: 0.8295 - val_loss: 0.7267\nEpoch 12/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8699 - loss: 0.6315 - val_accuracy: 0.8659 - val_loss: 0.6407\nEpoch 13/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.5687 - val_accuracy: 0.8795 - val_loss: 0.5739\nEpoch 14/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.5007 - val_accuracy: 0.8818 - val_loss: 0.5142\nEpoch 15/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.4442 - val_accuracy: 0.8932 - val_loss: 0.4692\nEpoch 16/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.3886 - val_accuracy: 0.9045 - val_loss: 0.4266\nEpoch 17/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9309 - loss: 0.3782 - val_accuracy: 0.9000 - val_loss: 0.3932\nEpoch 18/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9364 - loss: 0.3200 - val_accuracy: 0.9114 - val_loss: 0.3602\nEpoch 19/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.3141 - val_accuracy: 0.9205 - val_loss: 0.3359\nEpoch 20/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9353 - loss: 0.2792 - val_accuracy: 0.9295 - val_loss: 0.3107\nEpoch 21/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.2608 - val_accuracy: 0.9318 - val_loss: 0.2934\nEpoch 22/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9351 - loss: 0.2473 - val_accuracy: 0.9341 - val_loss: 0.2709\nEpoch 23/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.2276 - val_accuracy: 0.9364 - val_loss: 0.2592\nEpoch 24/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.2121 - val_accuracy: 0.9364 - val_loss: 0.2407\nEpoch 25/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9540 - loss: 0.2078 - val_accuracy: 0.9364 - val_loss: 0.2313\nEpoch 26/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9566 - loss: 0.1846 - val_accuracy: 0.9455 - val_loss: 0.2182\nEpoch 27/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9543 - loss: 0.1895 - val_accuracy: 0.9500 - val_loss: 0.2086\nEpoch 28/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.1679 - val_accuracy: 0.9432 - val_loss: 0.1991\nEpoch 29/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9687 - loss: 0.1606 - val_accuracy: 0.9477 - val_loss: 0.1923\nEpoch 30/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1434 - val_accuracy: 0.9432 - val_loss: 0.1810\nEpoch 31/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9618 - loss: 0.1471 - val_accuracy: 0.9500 - val_loss: 0.1769\nEpoch 32/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9677 - loss: 0.1359 - val_accuracy: 0.9614 - val_loss: 0.1726\nEpoch 33/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9664 - loss: 0.1265 - val_accuracy: 0.9568 - val_loss: 0.1654\nEpoch 34/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.1281 - val_accuracy: 0.9545 - val_loss: 0.1602\nEpoch 35/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.1229 - val_accuracy: 0.9591 - val_loss: 0.1566\nEpoch 36/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9638 - loss: 0.1193 - val_accuracy: 0.9591 - val_loss: 0.1525\nEpoch 37/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.1149 - val_accuracy: 0.9614 - val_loss: 0.1469\nEpoch 38/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9758 - loss: 0.1054 - val_accuracy: 0.9568 - val_loss: 0.1423\nEpoch 39/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9726 - loss: 0.1092 - val_accuracy: 0.9614 - val_loss: 0.1448\nEpoch 40/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9757 - loss: 0.0962 - val_accuracy: 0.9545 - val_loss: 0.1358\nEpoch 41/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0881 - val_accuracy: 0.9568 - val_loss: 0.1386\nEpoch 42/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0919 - val_accuracy: 0.9614 - val_loss: 0.1352\nEpoch 43/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.1004 - val_accuracy: 0.9636 - val_loss: 0.1316\nEpoch 44/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0833 - val_accuracy: 0.9591 - val_loss: 0.1309\nEpoch 45/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0891 - val_accuracy: 0.9636 - val_loss: 0.1294\nEpoch 46/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0773 - val_accuracy: 0.9636 - val_loss: 0.1282\nEpoch 47/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0810 - val_accuracy: 0.9659 - val_loss: 0.1225\nEpoch 48/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0831 - val_accuracy: 0.9614 - val_loss: 0.1199\nEpoch 49/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0748 - val_accuracy: 0.9614 - val_loss: 0.1164\nEpoch 50/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0675 - val_accuracy: 0.9614 - val_loss: 0.1201\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.1180 \nTest Accuracy: 96.14%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Static input for prediction\ninput_data = np.array([[50, 30, 20, 6.5, 60, 25, 500]])  # Example input values for N, P, K, pH, humidity, temp, conductivity\ninput_data_scaled = scaler.transform(input_data)  # Scale the input data\n\n# Predict the crop\nprediction = model.predict(input_data_scaled)\npredicted_class = np.argmax(prediction)\npredicted_crop = label_encoder.inverse_transform([predicted_class])\n\nprint(f\"Predicted Crop: {predicted_crop[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T15:02:25.873654Z","iopub.execute_input":"2025-01-01T15:02:25.874033Z","iopub.status.idle":"2025-01-01T15:02:25.983235Z","shell.execute_reply.started":"2025-01-01T15:02:25.874005Z","shell.execute_reply":"2025-01-01T15:02:25.982368Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\nPredicted Crop: rice\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Long Short-Term Memory (LSTM) Implementation","metadata":{}},{"cell_type":"code","source":"#  LSTM for Time-Series Soil Data\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/npk-crop-recmendation/crop_recommendation.csv')\n\n# Assuming time-series data preparation\n# If not already in time-series, convert it\n# Splitting features (X) and target (y)\nX = data[['N', 'P', 'K', 'ph', 'humidity', 'temperature', 'rainfall']].values\ny = data['label'].values\n\n# Encoding the target if it's categorical\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)\n\n# Reshape for LSTM input (samples, timesteps, features)\nX = X.reshape((X.shape[0], 1, X.shape[1]))\n\n# Splitting the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Building the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32))\nmodel.add(Dense(len(np.unique(y)), activation='softmax'))  # Adjust output neurons for classification\n\n# Compiling the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Training the model\nmodel.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n\n# Evaluating the model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T15:02:57.572785Z","iopub.execute_input":"2025-01-01T15:02:57.573142Z","iopub.status.idle":"2025-01-01T15:03:11.496924Z","shell.execute_reply.started":"2025-01-01T15:02:57.573117Z","shell.execute_reply":"2025-01-01T15:03:11.495962Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.1611 - loss: 3.0119 - val_accuracy: 0.5023 - val_loss: 2.6904\nEpoch 2/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5578 - loss: 2.4904 - val_accuracy: 0.6295 - val_loss: 1.8640\nEpoch 3/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6838 - loss: 1.6762 - val_accuracy: 0.7886 - val_loss: 1.2208\nEpoch 4/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7751 - loss: 1.1629 - val_accuracy: 0.8455 - val_loss: 0.8852\nEpoch 5/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8442 - loss: 0.8725 - val_accuracy: 0.8477 - val_loss: 0.6903\nEpoch 6/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.6871 - val_accuracy: 0.8909 - val_loss: 0.5394\nEpoch 7/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.5500 - val_accuracy: 0.9045 - val_loss: 0.4438\nEpoch 8/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.4565 - val_accuracy: 0.9205 - val_loss: 0.3773\nEpoch 9/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.3938 - val_accuracy: 0.9136 - val_loss: 0.3542\nEpoch 10/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.3456 - val_accuracy: 0.9227 - val_loss: 0.3073\nEpoch 11/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9419 - loss: 0.3040 - val_accuracy: 0.9250 - val_loss: 0.2708\nEpoch 12/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.2767 - val_accuracy: 0.9227 - val_loss: 0.2612\nEpoch 13/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9417 - loss: 0.2562 - val_accuracy: 0.9364 - val_loss: 0.2404\nEpoch 14/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9410 - loss: 0.2454 - val_accuracy: 0.9432 - val_loss: 0.2213\nEpoch 15/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.2096 - val_accuracy: 0.9091 - val_loss: 0.2339\nEpoch 16/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.2296 - val_accuracy: 0.9500 - val_loss: 0.1952\nEpoch 17/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.2052 - val_accuracy: 0.9318 - val_loss: 0.2052\nEpoch 18/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9454 - loss: 0.2099 - val_accuracy: 0.9341 - val_loss: 0.2143\nEpoch 19/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9550 - loss: 0.1833 - val_accuracy: 0.9500 - val_loss: 0.1672\nEpoch 20/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9550 - loss: 0.1766 - val_accuracy: 0.9455 - val_loss: 0.1843\nEpoch 21/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9338 - loss: 0.1986 - val_accuracy: 0.9432 - val_loss: 0.1704\nEpoch 22/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.1445 - val_accuracy: 0.9500 - val_loss: 0.1661\nEpoch 23/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9509 - loss: 0.1482 - val_accuracy: 0.9455 - val_loss: 0.1596\nEpoch 24/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1589 - val_accuracy: 0.9295 - val_loss: 0.2011\nEpoch 25/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1471 - val_accuracy: 0.9523 - val_loss: 0.1543\nEpoch 26/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1319 - val_accuracy: 0.9591 - val_loss: 0.1458\nEpoch 27/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1360 - val_accuracy: 0.9455 - val_loss: 0.1665\nEpoch 28/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1438 - val_accuracy: 0.9364 - val_loss: 0.1550\nEpoch 29/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1392 - val_accuracy: 0.9386 - val_loss: 0.1653\nEpoch 30/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.1433 - val_accuracy: 0.9591 - val_loss: 0.1560\nEpoch 31/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1304 - val_accuracy: 0.9409 - val_loss: 0.1573\nEpoch 32/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9547 - loss: 0.1319 - val_accuracy: 0.9273 - val_loss: 0.1631\nEpoch 33/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.1275 - val_accuracy: 0.9341 - val_loss: 0.1552\nEpoch 34/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1427 - val_accuracy: 0.9545 - val_loss: 0.1455\nEpoch 35/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.1200 - val_accuracy: 0.9523 - val_loss: 0.1305\nEpoch 36/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.1255 - val_accuracy: 0.9500 - val_loss: 0.1501\nEpoch 37/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9574 - loss: 0.1248 - val_accuracy: 0.9500 - val_loss: 0.1468\nEpoch 38/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.1201 - val_accuracy: 0.9477 - val_loss: 0.1573\nEpoch 39/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9589 - loss: 0.1138 - val_accuracy: 0.9500 - val_loss: 0.1346\nEpoch 40/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1223 - val_accuracy: 0.9409 - val_loss: 0.1534\nEpoch 41/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1270 - val_accuracy: 0.9477 - val_loss: 0.1475\nEpoch 42/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.1055 - val_accuracy: 0.9500 - val_loss: 0.1384\nEpoch 43/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1075 - val_accuracy: 0.9386 - val_loss: 0.1687\nEpoch 44/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.1030 - val_accuracy: 0.9477 - val_loss: 0.1358\nEpoch 45/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9533 - loss: 0.1257 - val_accuracy: 0.9591 - val_loss: 0.1350\nEpoch 46/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1042 - val_accuracy: 0.9523 - val_loss: 0.1407\nEpoch 47/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9699 - loss: 0.1065 - val_accuracy: 0.9477 - val_loss: 0.1361\nEpoch 48/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.0977 - val_accuracy: 0.9364 - val_loss: 0.1470\nEpoch 49/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9558 - loss: 0.1068 - val_accuracy: 0.9432 - val_loss: 0.1402\nEpoch 50/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9646 - loss: 0.1151 - val_accuracy: 0.9568 - val_loss: 0.1297\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1323 \nTest Accuracy: 95.68%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Static input for prediction\ninput_data = np.array([[50, 30, 20, 6.5, 60, 25, 500]])  # Example input values\ninput_data_scaled = scaler.transform(input_data)  # Scale the input\ninput_data_scaled = input_data_scaled.reshape((1, 1, input_data_scaled.shape[1]))  # Reshape for LSTM\n\n# Predict the crop\nprediction = model.predict(input_data_scaled)\npredicted_class = np.argmax(prediction)\npredicted_crop = label_encoder.inverse_transform([predicted_class])\n\nprint(f\"Predicted Crop: {predicted_crop[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T15:03:17.492694Z","iopub.execute_input":"2025-01-01T15:03:17.493081Z","iopub.status.idle":"2025-01-01T15:03:17.831855Z","shell.execute_reply.started":"2025-01-01T15:03:17.493055Z","shell.execute_reply":"2025-01-01T15:03:17.830936Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\nPredicted Crop: orange\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Autoencoder Implementation for Feature Reduction","metadata":{}},{"cell_type":"code","source":"#  Autoencoder for Dimensionality Reduction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Dense, Input\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/npk-crop-recmendation/crop_recommendation.csv')\n\n# Splitting features (X)\nX = data[['N', 'P', 'K', 'ph', 'humidity', 'temperature', 'rainfall']].values\n\n# Scaling features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Splitting the dataset for Autoencoder\nX_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n\n# Building the Autoencoder model\ninput_dim = X_train.shape[1]\n\n# Encoder\ninput_layer = Input(shape=(input_dim,))\nencoded = Dense(6, activation='relu')(input_layer)\nencoded = Dense(3, activation='relu')(encoded)  # Compressed representation\n\n# Decoder\ndecoded = Dense(6, activation='relu')(encoded)\ndecoded = Dense(input_dim, activation='sigmoid')(decoded)\n\n# Combine Encoder and Decoder into Autoencoder\nautoencoder = Model(inputs=input_layer, outputs=decoded)\n\n# Compile the model\nautoencoder.compile(optimizer='adam', loss='mse')\n\n# Train the Autoencoder\nautoencoder.fit(X_train, X_train, epochs=50, batch_size=32, validation_data=(X_test, X_test))\n\n# Extracting the encoder for dimensionality reduction\nencoder = Model(inputs=input_layer, outputs=encoded)\nX_train_encoded = encoder.predict(X_train)\nX_test_encoded = encoder.predict(X_test)\n\n# Display reduced features\nprint(\"Reduced feature representation (train):\", X_train_encoded[:5])\nprint(\"Reduced feature representation (test):\", X_test_encoded[:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T15:00:27.889003Z","iopub.execute_input":"2025-01-01T15:00:27.889408Z","iopub.status.idle":"2025-01-01T15:00:35.940498Z","shell.execute_reply.started":"2025-01-01T15:00:27.889377Z","shell.execute_reply":"2025-01-01T15:00:35.939463Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.2668 - val_loss: 1.1847\nEpoch 2/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1932 - val_loss: 1.1243\nEpoch 3/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1158 - val_loss: 1.0589\nEpoch 4/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0722 - val_loss: 1.0051\nEpoch 5/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0554 - val_loss: 0.9663\nEpoch 6/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0036 - val_loss: 0.9396\nEpoch 7/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9806 - val_loss: 0.9178\nEpoch 8/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9538 - val_loss: 0.8925\nEpoch 9/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9306 - val_loss: 0.8651\nEpoch 10/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8766 - val_loss: 0.8395\nEpoch 11/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8601 - val_loss: 0.8189\nEpoch 12/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8298 - val_loss: 0.8008\nEpoch 13/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8333 - val_loss: 0.7822\nEpoch 14/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7917 - val_loss: 0.7618\nEpoch 15/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7669 - val_loss: 0.7424\nEpoch 16/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7504 - val_loss: 0.7296\nEpoch 17/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7438 - val_loss: 0.7210\nEpoch 18/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7378 - val_loss: 0.7148\nEpoch 19/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7105 - val_loss: 0.7105\nEpoch 20/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7119 - val_loss: 0.7069\nEpoch 21/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7047 - val_loss: 0.7042\nEpoch 22/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7269 - val_loss: 0.7026\nEpoch 23/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7211 - val_loss: 0.7006\nEpoch 24/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7138 - val_loss: 0.6985\nEpoch 25/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7108 - val_loss: 0.6977\nEpoch 26/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7487 - val_loss: 0.6962\nEpoch 27/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7161 - val_loss: 0.6948\nEpoch 28/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7225 - val_loss: 0.6938\nEpoch 29/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7271 - val_loss: 0.6930\nEpoch 30/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7164 - val_loss: 0.6916\nEpoch 31/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7032 - val_loss: 0.6903\nEpoch 32/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7022 - val_loss: 0.6891\nEpoch 33/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7128 - val_loss: 0.6881\nEpoch 34/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7084 - val_loss: 0.6878\nEpoch 35/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6951 - val_loss: 0.6864\nEpoch 36/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7192 - val_loss: 0.6850\nEpoch 37/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7169 - val_loss: 0.6845\nEpoch 38/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7229 - val_loss: 0.6840\nEpoch 39/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7079 - val_loss: 0.6827\nEpoch 40/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7006 - val_loss: 0.6822\nEpoch 41/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7196 - val_loss: 0.6810\nEpoch 42/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7316 - val_loss: 0.6806\nEpoch 43/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6996 - val_loss: 0.6798\nEpoch 44/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7035 - val_loss: 0.6788\nEpoch 45/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7015 - val_loss: 0.6783\nEpoch 46/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7036 - val_loss: 0.6778\nEpoch 47/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6876 - val_loss: 0.6770\nEpoch 48/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6875 - val_loss: 0.6760\nEpoch 49/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7175 - val_loss: 0.6750\nEpoch 50/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6950 - val_loss: 0.6746\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \nReduced feature representation (train): [[ 5.6799703   9.746819   11.251341  ]\n [ 2.0469375   0.4401815   0.17523892]\n [ 3.2269125   0.34495115  0.5978637 ]\n [ 1.3373438   6.0780106   4.611292  ]\n [ 4.9621134   1.224684    2.238723  ]]\nReduced feature representation (test): [[ 3.4194167  12.03689     7.113207  ]\n [ 4.0644636  12.822825    7.5770264 ]\n [ 0.35894063  0.17438036  0.        ]\n [ 0.34095648  0.50744677  0.47805095]\n [ 0.          0.          9.260297  ]]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Autoencoder for Static Input Dimensionality Reduction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Input\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/npk-crop-recmendation/crop_recommendation.csv')\n\n# Splitting features (X)\nX = data[['N', 'P', 'K', 'ph', 'humidity', 'temperature', 'rainfall']].values\n\n# Scaling features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Splitting the dataset\nX_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n\n# Building the Autoencoder model\ninput_dim = X_train.shape[1]\n\n# Encoder\ninput_layer = Input(shape=(input_dim,))\nencoded = Dense(6, activation='relu')(input_layer)\nencoded = Dense(3, activation='relu')(encoded)  # Compressed representation\n\n# Decoder\ndecoded = Dense(6, activation='relu')(encoded)\ndecoded = Dense(input_dim, activation='sigmoid')(decoded)\n\n# Combine Encoder and Decoder into Autoencoder\nautoencoder = Model(inputs=input_layer, outputs=decoded)\n\n# Compile the model\nautoencoder.compile(optimizer='adam', loss='mse')\n\n# Train the Autoencoder\nautoencoder.fit(X_train, X_train, epochs=50, batch_size=32, validation_data=(X_test, X_test))\n\n# Extracting the encoder for dimensionality reduction\nencoder = Model(inputs=input_layer, outputs=encoded)\n\n# Static input for feature compression\ninput_data = np.array([[50, 30, 20, 6.5, 60, 25, 500]])  # Example input\ninput_data_scaled = scaler.transform(input_data)\n\n# Predict compressed features\ncompressed_features = encoder.predict(input_data_scaled)\nprint(f\"Compressed Feature Representation: {compressed_features}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T15:04:41.049279Z","iopub.execute_input":"2025-01-01T15:04:41.049697Z","iopub.status.idle":"2025-01-01T15:04:49.844787Z","shell.execute_reply.started":"2025-01-01T15:04:41.049664Z","shell.execute_reply":"2025-01-01T15:04:49.843956Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1939 - val_loss: 1.1397\nEpoch 2/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1852 - val_loss: 1.0809\nEpoch 3/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0986 - val_loss: 1.0223\nEpoch 4/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0293 - val_loss: 0.9679\nEpoch 5/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9719 - val_loss: 0.9247\nEpoch 6/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9530 - val_loss: 0.8924\nEpoch 7/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9392 - val_loss: 0.8700\nEpoch 8/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8974 - val_loss: 0.8550\nEpoch 9/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8592 - val_loss: 0.8442\nEpoch 10/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8761 - val_loss: 0.8360\nEpoch 11/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8372 - val_loss: 0.8290\nEpoch 12/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8547 - val_loss: 0.8230\nEpoch 13/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8720 - val_loss: 0.8179\nEpoch 14/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8318 - val_loss: 0.8130\nEpoch 15/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8250 - val_loss: 0.8086\nEpoch 16/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8319 - val_loss: 0.8041\nEpoch 17/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8381 - val_loss: 0.8000\nEpoch 18/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8673 - val_loss: 0.7959\nEpoch 19/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8224 - val_loss: 0.7919\nEpoch 20/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8211 - val_loss: 0.7877\nEpoch 21/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8022 - val_loss: 0.7813\nEpoch 22/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8076 - val_loss: 0.7649\nEpoch 23/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7606 - val_loss: 0.7453\nEpoch 24/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7485 - val_loss: 0.7314\nEpoch 25/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7528 - val_loss: 0.7236\nEpoch 26/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7262 - val_loss: 0.7191\nEpoch 27/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7200 - val_loss: 0.7151\nEpoch 28/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7369 - val_loss: 0.7097\nEpoch 29/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7262 - val_loss: 0.7022\nEpoch 30/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7081 - val_loss: 0.6977\nEpoch 31/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6969 - val_loss: 0.6933\nEpoch 32/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7024 - val_loss: 0.6892\nEpoch 33/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7028 - val_loss: 0.6855\nEpoch 34/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6923 - val_loss: 0.6822\nEpoch 35/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6914 - val_loss: 0.6785\nEpoch 36/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6908 - val_loss: 0.6753\nEpoch 37/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6936 - val_loss: 0.6720\nEpoch 38/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6757 - val_loss: 0.6688\nEpoch 39/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7050 - val_loss: 0.6652\nEpoch 40/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6916 - val_loss: 0.6620\nEpoch 41/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6663 - val_loss: 0.6592\nEpoch 42/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6598 - val_loss: 0.6567\nEpoch 43/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6867 - val_loss: 0.6546\nEpoch 44/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6765 - val_loss: 0.6524\nEpoch 45/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6762 - val_loss: 0.6507\nEpoch 46/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6751 - val_loss: 0.6493\nEpoch 47/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6709 - val_loss: 0.6480\nEpoch 48/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6725 - val_loss: 0.6468\nEpoch 49/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6698 - val_loss: 0.6460\nEpoch 50/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6617 - val_loss: 0.6449\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\nCompressed Feature Representation: [[14.750852   0.7969331  0.       ]]\n","output_type":"stream"}],"execution_count":12}]}